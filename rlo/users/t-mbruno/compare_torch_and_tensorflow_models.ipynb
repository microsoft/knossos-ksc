{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If notebook not at root of knossos:\n",
    "import os\n",
    "# os.chdir('/home/t-mbruno/projects/knossos')  # Path to knossos repo\n",
    "os.chdir('/home/t-salewi/knossos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlo import factory\n",
    "from rlo.expression import Expression\n",
    "from rlo import expr_sets\n",
    "from train_on_dataset import get_symtab_free_var_types\n",
    "from rlo.dataset import StateValueDataset\n",
    "from rlo.expression_util import make_toplevel\n",
    "from rlo import sparser\n",
    "from rlo.pipelines import graph_pipeline\n",
    "from rlo.pipelines.training_pipeline import _spec_to_input\n",
    "from rlo.torch_dataset import MultiEdgeTypeBatch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually specify configs for the torch and TF regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config obtained by running train_on_dataset.py and getting the config.json from the run\n",
    "tf_config = {\n",
    "    \"eager\": True,\n",
    "    \"scenario\": \"binding_simplify_astar\",\n",
    "    \"run_id\": \"binding_simplify_astar_2021_05_27_09_52_35_17255\",\n",
    "    \"gitlog\": \"41043ebc@t-salewi/pytorch-dummy+local_changes\",\n",
    "    \"output_dir\": \"outputs\",\n",
    "    \"force_gpu\": False,\n",
    "    \"gpu_memory_fraction\": None,\n",
    "    \"save_all_models\": False,\n",
    "    \"num_parallel\": 1,\n",
    "    \"dataset_path\": \"datasets/value_dataset.json\",\n",
    "    \"dist_plots\": None,\n",
    "    \"cost_bins\": 10,\n",
    "    \"value_bins\": 10,\n",
    "    \"node_bins\": 10,\n",
    "    \"exprs_per_generation\": 0,\n",
    "    \"use_subtree_match_edges\": True,\n",
    "    \"num_propagations\": 10,\n",
    "    \"nonlinear_messages\": False,\n",
    "    \"aggregation_over_edge_types\": \"sum\",\n",
    "    \"decoder_readout\": \"sum\",\n",
    "    \"message_from_sender_receiver\": False,\n",
    "    \"one_hot_embedding\": False,\n",
    "    \"hidden_dim\": 200,\n",
    "    \"output_hidden_dim\": 200,\n",
    "    \"gamma\": 0.1,\n",
    "    \"max_num_episodes_train\": 4096,\n",
    "    \"max_num_episodes_eval\": 100,\n",
    "    \"num_positive_examples\": 10,\n",
    "    \"simulation_depth\": 11,\n",
    "    \"maxing\": \"accumulator\",\n",
    "    \"min_epochs\": 10,\n",
    "    \"max_epochs\": 30,\n",
    "    \"num_repetitions\": 8,\n",
    "    \"graph_state_keep_prob\": 0.5,\n",
    "    \"output_keep_prob\": 0.5,\n",
    "    \"cost_normalization\": None,\n",
    "    \"patience_epochs\": 4,\n",
    "    \"num_generations\": None,\n",
    "    \"total_train_time\": 3600,\n",
    "    \"num_episode_clusters\": 5,\n",
    "    \"template_path\": None,\n",
    "    \"test_on_defs\": None,\n",
    "    \"train_on_defs\": None,\n",
    "    \"seed_all_reps\": None,\n",
    "    \"loss\": \"pinball=0.9\",\n",
    "    \"lr\": 0.0001,\n",
    "    \"grad_clip_value\": 0,\n",
    "    \"split\": 0.9,\n",
    "    \"value_bin_splits\": None,\n",
    "    \"time_bin_splits\": None,\n",
    "    \"episode_bin_splits\": None,\n",
    "    \"extra_plots\": [],\n",
    "    \"v2\": False,\n",
    "    \"verbose\": True,\n",
    "    \"dataset_refiners\": [\"best_across_generations_refiner\"],\n",
    "    \"train_search\": \"astar\",\n",
    "    \"eval_search\": \"astar\",\n",
    "    \"cost_per_step\": None,\n",
    "    \"max_gnn_train\": 1000,\n",
    "    \"max_gnn_eval\": 1000,\n",
    "    \"search_batch_size\": 16,\n",
    "    \"hybrid_merge_handling\": \"STOP\",\n",
    "    \"hybrid_prob_rollout\": 1.0,\n",
    "    # \"hybrid_alpha\": inf,\n",
    "    \"alpha_test\": 5.0,\n",
    "    \"init_alpha\": 1.0,\n",
    "    \"alpha_scaling_factor\": 1.1,\n",
    "    \"alpha_scaling_factor_fail\": 1.0,\n",
    "    \"sparse_gnn\": True,\n",
    "    \"tensorflow\": True,\n",
    "    \"num_gnn_blocks\": 1,\n",
    "    \"stacked_gnn_double_hidden\": False,\n",
    "    \"max_nodes_per_batch\": 10000,\n",
    "    \"cumsum\": None,\n",
    "    \"two_value_func\": None,\n",
    "    \"two_value_func_var_frac_train\": None,\n",
    "    \"rules\": \"binding_simplify_rules\",\n",
    "    \"test_exprs\": \"binding_simplify_expressions\",\n",
    "    \"train_exprs\": \"binding_simplify_expressions\",\n",
    "    \"oracle\": True,\n",
    "    \"extra_scenario_params\": \"+decoder_readout:sum+max_epochs:30+loss:pinball=0.9+tensorflow:True\",\n",
    "    \"result_save_path\": \"outputs/Run_binding_simplify_astar_2021_05_27_09_52_35_17255/0\",\n",
    "    \"repetition\": 0,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "tf_config[\"graph_state_keep_prob\"] = 0.999999999999\n",
    "torch_config = copy.deepcopy(tf_config)\n",
    "del torch_config['eager']\n",
    "torch_config['tensorflow'] = False\n",
    "assert tf_config['tensorflow'] == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the tensorflow and torch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the two models that should be the same\n",
    "tf_model = factory.regressor_from_config(tf_config)\n",
    "torch_model = factory.regressor_from_config(torch_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data into a framework-agnostic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "with open('datasets/value_dataset.json') as f:\n",
    "    dataset = json.load(f)['data_points']\n",
    "\n",
    "symtab, free_var_types = get_symtab_free_var_types(\n",
    "        expr_sets.get_expression_set(torch_config[\"train_exprs\"])\n",
    "    )\n",
    "\n",
    "dataset = StateValueDataset.build_from_triples(\n",
    "    (\n",
    "        t,\n",
    "        make_toplevel(\n",
    "            sparser.parse_expr(expr_str),\n",
    "            symtab=symtab,\n",
    "            free_var_types=free_var_types,\n",
    "        ),\n",
    "        v,\n",
    "    )\n",
    "    for t, expr_str, v in dataset\n",
    ")\n",
    "\n",
    "raw_examples = dataset.get_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data-loading utilities for torch and tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch data converter\n",
    "data_converter = factory.data_converter_from_config(torch_config)\n",
    "torch_graph = data_converter.prepare_exprtab(raw_examples[0][0])\n",
    "print(torch_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow data converter\n",
    "pipeline = graph_pipeline.SparsePipeline(use_subtree_match_edges=tf_config['use_subtree_match_edges'])\n",
    "np_graph = pipeline.prepare_example(raw_examples[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check torch inputs and tf inputs are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 9 edge types\n",
    "assert len(np_graph.edge_indices) == len(torch_graph.edge_indices) == 9\n",
    "# Torch and numpy edges should be the same, just transposed.\n",
    "for np_edges, torch_edges in zip(np_graph.edge_indices, torch_graph.edge_indices):\n",
    "    np.testing.assert_equal(np_edges.T, torch_edges.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise tf_model and its layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pipeline.batched_spec\n",
    "inputs = tf.nest.map_structure(_spec_to_input, pipeline.batched_spec)\n",
    "# print(inputs.keys())\n",
    "tf_model.keras_model.build_and_compile(inputs=inputs)\n",
    "tf_model.keras_model.built = True  # Otherwise we get ValueError. build_and_compile method says something about why it calls 'call' not 'build'\n",
    "# tf_model.keras_model.summary()\n",
    "\n",
    "def print_details(model):\n",
    "    try:\n",
    "        model.summary()\n",
    "    except Exception:\n",
    "        return\n",
    "    if hasattr(model, 'layers'):\n",
    "        for layer in model.layers:\n",
    "            \n",
    "            print_details(layer)\n",
    "            \n",
    "print_details(tf_model.keras_model)        \n",
    "# tf_model.keras_model.layers[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise torch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch_model.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_parameters(m):\n",
    "    return sum(np.prod(p.shape) for p in m.parameters())\n",
    "\n",
    "print('Whole torch model', num_parameters(torch_model.model))\n",
    "print('Torch encoder', num_parameters(torch_model.model.encoder))   # We have an extra 600 params in encoder\n",
    "print('Torch regressor', num_parameters(torch_model.model.regressor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print-out and compare shapes of parameter tensors for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_tf_weights_shapes(weights):\n",
    "    for weight in weights:\n",
    "        print(f\"{weight.name:<70}\\t{weight.shape}\")\n",
    "        \n",
    "def summarise_torch_weights_shapes(model: torch.nn.Module):\n",
    "    for name, param in torch_model.model.named_parameters():\n",
    "        print(f\"{name:<70}\\t{param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 10 + \" Tensorflow \" + \"-\" * 10)\n",
    "summarise_tf_weights_shapes(tf_model.keras_model.weights)\n",
    "print(\"-\" * 10 + \" Torch \" + \"-\" * 10)\n",
    "summarise_torch_weights_shapes(torch_model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper function for getting keras parameters by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_by_name(keras_model, param_name):\n",
    "    params = [x.numpy() for x in keras_model.weights if x.name == param_name]\n",
    "    if len(params) == 0:\n",
    "        raise ValueError(f\"No such parameter {param_name} in model.\")\n",
    "    elif len(params) > 1:\n",
    "        raise ValueError(f\"There are multiple parameters matching name {param_name}\")\n",
    "    return params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make plots comparing parameter distributions in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Embeddding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embeddings\n",
    "embedding_weights_tf = get_param_by_name(tf_model.keras_model, \"sparse_gnn_encoder/embedding/embeddings:0\")\n",
    "embedding_weights_torch = torch_model.model.encoder.embedding.weight.detach().numpy()\n",
    "plt.hist(embedding_weights_tf.ravel(), alpha=0.5, label=\"tensorflow\")\n",
    "plt.hist(embedding_weights_torch.ravel(), alpha=0.5, label=\"Torch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = torch.nn.Embedding(num_embeddings=28, embedding_dim=200)\n",
    "# torch.nn.init.xavier_uniform_(embedding.weight)\n",
    "# plt.hist(embedding.weight.detach().numpy().ravel(), bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Message functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_types = torch_model.model.encoder.gnn.gnn_blocks[0].num_edge_types\n",
    "print(f'There are {num_edge_types} edge types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare message_functions\n",
    "fig, axes = plt.subplots(ncols=2, nrows=num_edge_types, figsize=(12,3.5 * num_edge_types))\n",
    "\n",
    "for i in range(num_edge_types):\n",
    "    kernel_weights_tf = next(x.numpy() for x in tf_model.keras_model.weights if x.name == f\"sparse_gnn_encoder/sparse_gnn/kernel{i}:0\")\n",
    "    kernel_bias_tf = next(x.numpy() for x in tf_model.keras_model.weights if x.name == f\"sparse_gnn_encoder/sparse_gnn/bias:0\")[i]\n",
    "#     print(kernel_bias_torch)\n",
    "\n",
    "    kernel_weights_torch = next(\n",
    "        x.detach().numpy() for name, x in torch_model.model.named_parameters() if name == f\"encoder.gnn.gnn_blocks.0.message_functions.{i}.weight\")\n",
    "    kernel_bias_torch = next(\n",
    "        x.detach().numpy() for name, x in torch_model.model.named_parameters() if name == f\"encoder.gnn.gnn_blocks.0.message_functions.{i}.bias\")\n",
    "    \n",
    "    axes[i, 0].hist(kernel_weights_tf.ravel(), alpha=0.5, label=\"tensorflow\", density=True)\n",
    "    axes[i, 0].hist(kernel_weights_torch.ravel(), alpha=0.5, label=\"Torch\", density=True)\n",
    "    axes[i, 0].set_title(\"Message function weights\")\n",
    "    axes[i, 1].hist(kernel_bias_tf.ravel(), alpha=0.5, label=\"tensorflow\", density=True)\n",
    "    axes[i, 1].hist(kernel_bias_torch.ravel(), alpha=0.5, label=\"Torch\", density=True)\n",
    "    axes[i, 1].set_xlim(kernel_bias_torch.min(), kernel_bias_torch.max())\n",
    "    axes[i, 1].set_title(\"Message function bias\")\n",
    "    axes[i, 1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Is kernel bias in tensorflow == 0 for all?\n",
    "kernel_bias_tf = next(x.numpy() for x in tf_model.keras_model.weights if x.name == f\"sparse_gnn_encoder/sparse_gnn/bias:0\")\n",
    "print(np.all(kernel_bias_tf.ravel() == 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print histograms for all parameter tensors (TORCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "num_param_tensors = len(list(torch_model.model.parameters()))\n",
    "color = \"black\"\n",
    "fig, axes = plt.subplots(ncols=num_param_tensors, nrows=1, figsize=(7 * num_param_tensors,5))\n",
    "\n",
    "for i, (name, param) in enumerate(torch_model.model.named_parameters()):\n",
    "    axes[i].hist(param.detach().numpy().ravel(), color=color, density=True)\n",
    "    axes[i].set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print histograms for all parameter tensors (TENSORFLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare message_functions\n",
    "num_param_tensors = len(list(tf_model.keras_model.weights))\n",
    "color = \"orange\"\n",
    "fig, axes = plt.subplots(ncols=num_param_tensors, nrows=1, figsize=(7 * num_param_tensors,5))\n",
    "\n",
    "for i, weight in enumerate(tf_model.keras_model.weights):\n",
    "    axes[i].hist(weight.numpy().ravel(), color=color, density=True)\n",
    "    axes[i].set_title(weight.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specify matching sets of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to print out parameter name for copy pasting later in the code\n",
    "\n",
    "def summarise_tf_weights_names(weights):\n",
    "    for weight in weights:\n",
    "        print(f\"{weight.name:<70}\")\n",
    "        \n",
    "def summarise_torch_weights_names(model: torch.nn.Module):\n",
    "    for name, param in torch_model.model.named_parameters():\n",
    "        print(f\"{name:<70}\")\n",
    "        \n",
    "summarise_tf_weights_names(tf_model.keras_model.weights)\n",
    "print(\"-\"*40)\n",
    "summarise_torch_weights_names(torch_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = {}  # map (torch_name -> (tf_name, extractor_fn))\n",
    "from functools import partial\n",
    "def do_nothing(x): return x\n",
    "def transpose(x): return x.T\n",
    "def getitem(x,i):\n",
    "    return x[i]\n",
    "\n",
    "for i in range(num_edge_types):\n",
    "    name_mapping[f\"encoder.gnn.gnn_blocks.0.message_functions.{i}.bias\"] = (f\"sparse_gnn_encoder/sparse_gnn/bias:0\", partial(getitem, i=i))\n",
    "    name_mapping[f\"encoder.gnn.gnn_blocks.0.message_functions.{i}.weight\"] = (f\"sparse_gnn_encoder/sparse_gnn/kernel{i}:0\", do_nothing)\n",
    "name_mapping[f\"encoder.embedding.weight\"] = (f\"sparse_gnn_encoder/embedding/embeddings:0\", do_nothing)\n",
    "name_mapping[f\"regressor.mlp.1.weight\"] = (f\"gated_regression/out_layer/dense/kernel:0\", transpose)\n",
    "name_mapping[f\"regressor.mlp.1.bias\"] = (f\"gated_regression/out_layer/dense/bias:0\", do_nothing)\n",
    "name_mapping[f\"regressor.mlp.3.weight\"] = (f\"gated_regression/regression_transform/dense_2/kernel:0\", transpose)\n",
    "\n",
    "name_mapping[f\"regressor.mlp.3.bias\"] = (f\"gated_regression/regression_transform/dense_2/bias:0\", do_nothing)\n",
    "name_mapping[f\"regressor.gate.1.weight\"] = (f\"gated_regression/regression_gate/dense_1/kernel:0\", transpose)\n",
    "name_mapping[f\"regressor.gate.1.bias\"] = (f\"gated_regression/regression_gate/dense_1/bias:0\", do_nothing)\n",
    "# RNN (ignore bias)\n",
    "name_mapping[\"encoder.gnn.gnn_blocks.0.rnn.weight_ih\"] = (\"sparse_gnn_encoder/sparse_gnn/seeded_gru_cell/kernel:0\", transpose)\n",
    "name_mapping[\"encoder.gnn.gnn_blocks.0.rnn.weight_hh\"] = (\"sparse_gnn_encoder/sparse_gnn/seeded_gru_cell/recurrent_kernel:0\", transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tf_weights_to_torch_model(model: torch.nn.Module, keras_model):\n",
    "    state_dict = model.state_dict()\n",
    "    keys_old = set(state_dict.keys())\n",
    "    keys_new = set(name_mapping.keys())\n",
    "    print('torch keys not updated:', keys_old - keys_new)\n",
    "    print('keys added:', keys_new - keys_old)\n",
    "    for torch_name, (tf_name, fn) in name_mapping.items():\n",
    "        state_dict[torch_name] = torch.FloatTensor(fn(get_param_by_name(keras_model, tf_name)))\n",
    "    model.load_state_dict(state_dict)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign TF parameters to torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_tf_weights_to_torch_model(torch_model.model, tf_model.keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify that some parameters are indeed the same\n",
    "# Commented out because it is slow\n",
    "\n",
    "# ncols=3\n",
    "# fig, axes = plt.subplots(ncols=ncols, nrows=len(name_mapping)//ncols + 1,figsize=(50, 100))\n",
    "# state_dict = torch_model.model.state_dict()\n",
    "\n",
    "# for n, (torch_name, (tf_name, fn)) in enumerate(name_mapping.items()):\n",
    "#     ax = axes[n//ncols][n%ncols]\n",
    "#     ax.plot(state_dict[torch_name], fn(get_param_by_name(tf_model.keras_model, tf_name)),'.')\n",
    "#     ax.set_title(torch_name, fontsize=20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare output distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a torch graph\n",
    "torch_graph = data_converter.prepare_exprtab(raw_examples[0][0])\n",
    "\n",
    "# Make a tf graph (same data, different format)\n",
    "np_graph = pipeline.prepare_example(raw_examples[0][0])\n",
    "tf_input = tf.nest.map_structure(tf.convert_to_tensor, np_graph._asdict())\n",
    "tf_input['node_type'] = tf_input['node_reps']\n",
    "tf_input['node_row_splits'] = [0, len(tf_input['node_reps'])]\n",
    "tf_input['adjacency'] = tf_input['edge_indices']\n",
    "del tf_input['node_reps']\n",
    "del tf_input['edge_indices']\n",
    "\n",
    "print('tf_input', tf_input)\n",
    "print('torch_input', torch_graph.x, torch_graph.edge_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward passes through tf_model and torch_model with the same inputs\n",
    "\n",
    "tf_output = tf_model.keras_model(tf_input, training=False)\n",
    "\n",
    "print('tf model outputs', tf_output)\n",
    "print('mean abs', tf.math.reduce_mean(tf.math.abs(tf_output)))\n",
    "torch_batch = MultiEdgeTypeBatch.from_data_list([torch_graph])\n",
    "\n",
    "torch_model.model.eval()\n",
    "torch_output = torch_model.model(torch_batch)\n",
    "print('torch model outputs', torch_output, 'mean abs', torch.mean(torch.abs(torch_output)), ' std', torch_output.std())\n",
    "\n",
    "plt.plot(torch_output.detach().numpy(), tf_output,'.')\n",
    "plt.xlabel('torch')\n",
    "plt.ylabel('tf')\n",
    "\n",
    "def plot_cumdist(vals, label):\n",
    "    tmp = np.sort(vals.numpy().ravel())\n",
    "    n = len(tmp)\n",
    "    plt.plot(np.arange(n)/n, tmp, label=label)\n",
    "    plt.xlabel('cum prob')\n",
    "    plt.ylabel('value')\n",
    "\n",
    "    \n",
    "def compare_cumdist(torch_vals, tf_vals, title):\n",
    "    plt.figure()\n",
    "    plot_cumdist(torch_vals.detach(), label='torch')\n",
    "    plot_cumdist(tf_vals, label='tf')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "compare_cumdist(torch_output, tf_output, 'Full-model outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_gnn_output = torch_model.model.encoder(x=torch_batch.x, edge_indices=torch_batch.edge_indices)\n",
    "tf_gnn_output = tf_model.keras_model.encoder(tf_input)\n",
    "compare_cumdist(torch_gnn_output, tf_gnn_output, 'Encoder only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare just the Embedding at the input to the GNN\n",
    "\n",
    "tf_output = tf_model.keras_model.encoder.initial_node_embedding(tf_input['node_type'], training=False)\n",
    "torch_output = torch_model.model.encoder.embedding(torch_batch.x)\n",
    "compare_cumdist(torch_output, tf_output, 'Embedding only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_regressor_input = np.random.rand(5, 400).astype(np.float32)\n",
    "torch_input = torch.tensor(random_regressor_input, dtype=torch.float)\n",
    "torch_output = torch_model.model.regressor(torch_input, \n",
    "                                           batch_assignment = torch.tensor([0,0,0,0,0]))\n",
    "tf_output = tf_model.keras_model.regression(random_regressor_input, [0, 5])\n",
    "compare_cumdist(torch_output, tf_output, 'Regressor only')\n",
    "tf_regressor = tf_model.keras_model.regression\n",
    "torch_regressor = torch_model.model.regressor\n",
    "\n",
    "\n",
    "tf_gated_outputs = tf_regressor.regression_gate(random_regressor_input) * tf_regressor.regression_transform(\n",
    "            tf_regressor.out_layer(random_regressor_input)\n",
    "        )\n",
    "torch_gated_outputs = torch_regressor.gate(torch_input) * torch_regressor.mlp(torch_input)\n",
    "\n",
    "compare_cumdist(torch_gated_outputs,tf_gated_outputs,  'pre-pooling')\n",
    "\n",
    "tf_gated_outputs = tf_regressor.regression_gate(random_regressor_input) \n",
    "torch_gated_outputs = torch_regressor.gate(torch_input) \n",
    "compare_cumdist(torch_gated_outputs, tf_gated_outputs, 'gates')\n",
    "\n",
    "\n",
    "torch_x = torch_regressor.mlp(torch_input)\n",
    "tf_x = tf_regressor.regression_transform(\n",
    "            tf_regressor.out_layer(random_regressor_input)\n",
    "        )\n",
    "compare_cumdist(torch_x, tf_x, 'mlp')\n",
    "# Plot the model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from rlo.model.gru import GRU\n",
    "\n",
    "tf_gru = tf_model.keras_model.encoder.gnn.gru_cell\n",
    "print('TF gru cell has type', type(tf_gru), 'dropout', tf_gru.dropout)\n",
    "\n",
    "\n",
    "# Examine properties of the tf_gru\n",
    "# These determine what happens in 'call' method of this class\n",
    "print('TF GRU settings:')\n",
    "for k in ['use_bias', 'reset_after', 'implementation', 'dropout', 'activation', 'recurrent_activation']:\n",
    "    if not k.startswith('_'):\n",
    "        try:\n",
    "            print(f\"{k:<20}\", getattr(tf_gru, k))\n",
    "        except Exception:\n",
    "            print('cannot print', k)\n",
    "\n",
    "            \n",
    "torch_gru = torch_model.model.encoder.gnn.gnn_blocks[0].rnn\n",
    "print('Torch GRU cell has type', type(torch_gru), 'dropout', torch_gru._dropout)\n",
    "\n",
    "# Define some random inputs\n",
    "gru_input_np = np.random.rand(5,200).astype(np.float32) + np.arange(5)[:, None].astype(np.float32)\n",
    "gru_hidden_np = np.random.rand(5,200).astype(np.float32) + np.arange(5)[:, None].astype(np.float32)\n",
    "\n",
    "# COmpare output on the random inputs\n",
    "tf_output, _ = tf_gru(inputs=gru_input_np, states=gru_hidden_np)\n",
    "torch_output = torch_gru(input=torch.tensor(gru_input_np), hidden=torch.tensor(gru_hidden_np))\n",
    "compare_cumdist(torch_output, tf_output, 'gru cell')\n",
    "\n",
    "# New GRU is a torch copy of tensorflow GRU behaviour\n",
    "new_gru = GRU(input_size = torch_gru.input_size, weight_ih = torch_gru.weight_ih, weight_hh = torch_gru.weight_hh)\n",
    "new_torch_output = new_gru(inputs=torch.tensor(gru_input_np), states=torch.tensor(gru_hidden_np))\n",
    "\n",
    "# ... and indeed it gives same outputs, unlike the old one\n",
    "compare_cumdist(new_torch_output, tf_output, 'new torch gru cell')\n",
    "plt.figure()\n",
    "plt.plot(torch_output.detach().numpy().ravel(), tf_output.numpy().ravel(),'.', label='old torch')\n",
    "plt.plot(new_torch_output.detach().numpy().ravel(), tf_output.numpy().ravel(), '.', label='new torch')\n",
    "plt.legend()\n",
    "plt.xlabel('torch'); plt.ylabel('tf')\n",
    "plt.title('TF output vs torch output')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace torch GRU with something just like the tensorflow GRU in the GNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(torch_model.model.encoder.gnn.gnn_blocks) ==1\n",
    "torch_model.model.encoder.gnn.gnn_blocks[0] = new_gru\n",
    "old_torch_gnn_output = torch_gnn_output\n",
    "torch_gnn_output = torch_model.model.encoder(x=torch_batch.x, edge_indices=torch_batch.edge_indices)\n",
    "tf_gnn_output = tf_model.keras_model.encoder(tf_input)\n",
    "compare_cumdist(torch_gnn_output, tf_gnn_output, 'Encoder only, with new GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare tf vs. torch gradients for GNN (encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch_model.model.encoder.zero_grad()\n",
    "torch_gnn_loss  = torch_gnn_output.sum()\n",
    "torch_gnn_loss.backward()\n",
    "torch_embed_gradients = torch_model.model.encoder.embedding.weight.grad\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tf_gnn_output = tf_model.keras_model.encoder(tf_input)\n",
    "    tf_gnn_loss = tf.math.reduce_sum(tf_gnn_output)\n",
    "\n",
    "dir(tf_model.keras_model.encoder.initial_node_embedding)\n",
    "slices = tape.gradient(tf_gnn_loss, tf_model.keras_model.encoder.initial_node_embedding.weights)\n",
    "\n",
    "tf_grads = np.zeros((28,200))\n",
    "print(tf_grads.shape)\n",
    "print(slices[0].values.shape)\n",
    "for i, val in zip(slices[0].indices, slices[0].values):\n",
    "    tf_grads[i] = val.numpy()\n",
    "\n",
    "\n",
    "compare_cumdist(torch_embed_gradients, tf.convert_to_tensor(tf_grads), 'embedding gradients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "203e31d0dc4293755351bd748597880d3a2aaa42f38732bffd939de1ebd49a2a"
   }
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
