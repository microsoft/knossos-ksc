;; AUTOGENERATED FROM obj/hf-bert-to-onnx/bert1.onnx
(def torch-jit-export None ((input_ids : (Vec Integer)) (attention_mask : (Vec Integer)) (token_type_ids : (Vec Integer)))
  (let (%187 (vec 0))
  (let (%188 (vec 1))
  (let (%189 2.0)
  (let (%190 (load-from-onnx-float32 768 768 "%190"))
  (let (%191 (load-from-onnx-float32 768 768 "%191"))
  (let (%192 (load-from-onnx-float32 768 768 "%192"))
  (let (%193 (vec 12))
  (let (%194 (vec 64))
  (let (%195 (vec 12))
  (let (%196 (vec 64))
  (let (%197 (vec 12))
  (let (%198 (vec 64))
  (let (%199 (vec 768))
  (let (%200 (load-from-onnx-float32 768 768 "%200"))
  (let (%201 2.0)
  (let (%202 (load-from-onnx-float32 768 3072 "%202"))
  (let (%203 (load-from-onnx-float32 3072 768 "%203"))
  (let (%204 2.0)
  (let (%205 (load-from-onnx-float32 768 2 "%205"))
  (let (bert.embeddings.LayerNorm.bias (load-from-onnx-float32 768 "bert.embeddings.LayerNorm.bias"))
  (let (bert.embeddings.LayerNorm.weight (load-from-onnx-float32 768 "bert.embeddings.LayerNorm.weight"))
  (let (bert.embeddings.position_embeddings.weight (load-from-onnx-float32 512 768 "bert.embeddings.position_embeddings.weight"))
  (let (bert.embeddings.position_ids (load-from-onnx-int64 1 512 "bert.embeddings.position_ids"))
  (let (bert.embeddings.token_type_embeddings.weight (load-from-onnx-float32 2 768 "bert.embeddings.token_type_embeddings.weight"))
  (let (bert.embeddings.word_embeddings.weight (load-from-onnx-float32 30522 768 "bert.embeddings.word_embeddings.weight"))
  (let (bert.encoder.layer.0.attention.output.LayerNorm.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.attention.output.LayerNorm.bias"))
  (let (bert.encoder.layer.0.attention.output.LayerNorm.weight (load-from-onnx-float32 768 "bert.encoder.layer.0.attention.output.LayerNorm.weight"))
  (let (bert.encoder.layer.0.attention.output.dense.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.attention.output.dense.bias"))
  (let (bert.encoder.layer.0.attention.self.key.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.attention.self.key.bias"))
  (let (bert.encoder.layer.0.attention.self.query.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.attention.self.query.bias"))
  (let (bert.encoder.layer.0.attention.self.value.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.attention.self.value.bias"))
  (let (bert.encoder.layer.0.intermediate.dense.bias (load-from-onnx-float32 3072 "bert.encoder.layer.0.intermediate.dense.bias"))
  (let (bert.encoder.layer.0.output.LayerNorm.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.output.LayerNorm.bias"))
  (let (bert.encoder.layer.0.output.LayerNorm.weight (load-from-onnx-float32 768 "bert.encoder.layer.0.output.LayerNorm.weight"))
  (let (bert.encoder.layer.0.output.dense.bias (load-from-onnx-float32 768 "bert.encoder.layer.0.output.dense.bias"))
  (let (qa_outputs.bias (vec 0.0 0.0))
  (let ($beg_of_internal_inits #|Begin of internal initializers|#  99999)
  (let ($end_of_inits #|End of initializers|#  99999)
  (let (%27 (Unsqueeze attention_mask (vec 1)))
  (let (%28 (Unsqueeze %27 (vec 2)))
  (let (%29 (Cast_FLOAT %28))
  (let (%30 (Constant 1.0))
  (let (%31 (Sub %30 %29))
  (let (%32 (Constant -10000.0))
  (let (%33 (Mul %31 %32))
  (let (%34 (Shape input_ids))
  (let (%35 (Constant 1))
  (let (%36 (Gather %34 %35 0))
  (let (%40 (Unsqueeze %36 (vec 0)))
  (let (%42 (Constant (vec 1)))
  (let (%43 (Slice bert.embeddings.position_ids %187 %40 %188 %42))
  (let (%44 (Gather bert.embeddings.word_embeddings.weight input_ids 0))
  (let (%45 (Gather bert.embeddings.position_embeddings.weight %43 0))
  (let (%46 (Gather bert.embeddings.token_type_embeddings.weight token_type_ids 0))
  (let (%47 (Add %44 %45))
  (let (%48 (Add %47 %46))
  (let (%50 (ReduceMean %48 (vec -1) 1))
  (let (%51 (Sub %48 %50))
  (let (%52 (Cast_FLOAT %51))
  (let (%54 (Pow %52 %189))
  (let (%55 (ReduceMean %54 (vec -1) 1))
  (let (%56 (Constant 9.999999960041972e-13))
  (let (%57 (Add %55 %56))
  (let (%58 (Sqrt %57))
  (let (%59 (Div %51 %58))
  (let (%60 (Mul %59 bert.embeddings.LayerNorm.weight))
  (let (%61 (Add %60 bert.embeddings.LayerNorm.bias))
  (let (%63 (MatMul %61 %190))
  (let (%64 (Add %63 bert.encoder.layer.0.attention.self.query.bias))
  (let (%66 (MatMul %61 %191))
  (let (%67 (Add %66 bert.encoder.layer.0.attention.self.key.bias))
  (let (%69 (MatMul %61 %192))
  (let (%70 (Add %69 bert.encoder.layer.0.attention.self.value.bias))
  (let (%71 (Shape %64))
  (let (%72 (Constant 0))
  (let (%73 (Gather %71 %72 0))
  (let (%74 (Shape %64))
  (let (%75 (Constant 1))
  (let (%76 (Gather %74 %75 0))
  (let (%79 (Unsqueeze %73 (vec 0)))
  (let (%80 (Unsqueeze %76 (vec 0)))
  (let (%83 (Concat %79 %80 %193 %194 0))
  (let (%84 (Reshape %64 %83))
  (let (%85 (Transpose %84 (vec 0 2 1 3)))
  (let (%86 (Shape %67))
  (let (%87 (Constant 0))
  (let (%88 (Gather %86 %87 0))
  (let (%89 (Shape %67))
  (let (%90 (Constant 1))
  (let (%91 (Gather %89 %90 0))
  (let (%94 (Unsqueeze %88 (vec 0)))
  (let (%95 (Unsqueeze %91 (vec 0)))
  (let (%98 (Concat %94 %95 %195 %196 0))
  (let (%99 (Reshape %67 %98))
  (let (%100 (Shape %70))
  (let (%101 (Constant 0))
  (let (%102 (Gather %100 %101 0))
  (let (%103 (Shape %70))
  (let (%104 (Constant 1))
  (let (%105 (Gather %103 %104 0))
  (let (%108 (Unsqueeze %102 (vec 0)))
  (let (%109 (Unsqueeze %105 (vec 0)))
  (let (%112 (Concat %108 %109 %197 %198 0))
  (let (%113 (Reshape %70 %112))
  (let (%114 (Transpose %113 (vec 0 2 1 3)))
  (let (%115 (Transpose %99 (vec 0 2 3 1)))
  (let (%116 (MatMul %85 %115))
  (let (%117 (Constant 8.0))
  (let (%118 (Div %116 %117))
  (let (%119 (Add %118 %33))
  (let (%120 (Softmax %119 3))
  (let (%121 (MatMul %120 %114))
  (let (%122 (Transpose %121 (vec 0 2 1 3)))
  (let (%123 (Shape %122))
  (let (%124 (Constant 0))
  (let (%125 (Gather %123 %124 0))
  (let (%126 (Shape %122))
  (let (%127 (Constant 1))
  (let (%128 (Gather %126 %127 0))
  (let (%130 (Unsqueeze %125 (vec 0)))
  (let (%131 (Unsqueeze %128 (vec 0)))
  (let (%133 (Concat %130 %131 %199 0))
  (let (%134 (Reshape %122 %133))
  (let (%136 (MatMul %134 %200))
  (let (%137 (Add %136 bert.encoder.layer.0.attention.output.dense.bias))
  (let (%138 (Add %137 %61))
  (let (%140 (ReduceMean %138 (vec -1) 1))
  (let (%141 (Sub %138 %140))
  (let (%142 (Cast_FLOAT %141))
  (let (%144 (Pow %142 %201))
  (let (%145 (ReduceMean %144 (vec -1) 1))
  (let (%146 (Constant 9.999999960041972e-13))
  (let (%147 (Add %145 %146))
  (let (%148 (Sqrt %147))
  (let (%149 (Div %141 %148))
  (let (%150 (Mul %149 bert.encoder.layer.0.attention.output.LayerNorm.weight))
  (let (%151 (Add %150 bert.encoder.layer.0.attention.output.LayerNorm.bias))
  (let (%153 (MatMul %151 %202))
  (let (%154 (Add %153 bert.encoder.layer.0.intermediate.dense.bias))
  (let (%155 (Constant 1.4142135381698608))
  (let (%156 (Div %154 %155))
  (let (%157 (Erf %156))
  (let (%158 (Constant 1.0))
  (let (%159 (Add %157 %158))
  (let (%160 (Mul %154 %159))
  (let (%161 (Constant 0.5))
  (let (%162 (Mul %160 %161))
  (let (%164 (MatMul %162 %203))
  (let (%165 (Add %164 bert.encoder.layer.0.output.dense.bias))
  (let (%166 (Add %165 %151))
  (let (%168 (ReduceMean %166 (vec -1) 1))
  (let (%169 (Sub %166 %168))
  (let (%170 (Cast_FLOAT %169))
  (let (%172 (Pow %170 %204))
  (let (%173 (ReduceMean %172 (vec -1) 1))
  (let (%174 (Constant 9.999999960041972e-13))
  (let (%175 (Add %173 %174))
  (let (%176 (Sqrt %175))
  (let (%177 (Div %169 %176))
  (let (%178 (Mul %177 bert.encoder.layer.0.output.LayerNorm.weight))
  (let (%179 (Add %178 bert.encoder.layer.0.output.LayerNorm.bias))
  (let (%181 (MatMul %179 %205))
  (let (%182 (Add %181 qa_outputs.bias))
  (let ((%183 %184) (Split %182 (vec 1 1) -1))
  (let (output_0 (Squeeze %183 (vec -1)))
  (let (output_1 (Squeeze %184 (vec -1)))
  output_1)))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))

(def main None ((input_ids : (Vec Integer)) (attention_mask : (Vec Integer)) (token_type_ids : (Vec Integer)))
  (torch-jit-export input_ids attention_mask token_type_ids))

