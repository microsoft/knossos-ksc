{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "From https://lernapparat.de/jit-optimization-intro/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def fn(x):\n",
    "    for i in range(x.dim()):\n",
    "        x = x * x\n",
    "    return x\n",
    "\n",
    "script_fn = torch.jit.script(fn)\n",
    "trace_fn = torch.jit.trace(fn, [torch.randn(5, 5)])\n",
    "\n",
    "print(script_fn.code)\n",
    "\n",
    "print(trace_fn.code)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def fn(x: Tensor) -> Tensor:\n",
      "  x0 = x\n",
      "  for i in range(torch.dim(x)):\n",
      "    x0 = torch.mul(x0, x0)\n",
      "  return x0\n",
      "\n",
      "def fn(x: Tensor) -> Tensor:\n",
      "  x0 = torch.mul(x, x)\n",
      "  return torch.mul(x0, x0)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "@torch.jit.script\n",
    "def conv1(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    (na,) = a.size()\n",
    "    (nb,) = b.size()\n",
    "    out = torch.empty(na - nb + 1)\n",
    "    for ia in range(na - nb + 1):\n",
    "        out[ia] = sum(torch.tensor([a[ia + ib] * b[ib] for ib in range(na)]))\n",
    "    return out\n",
    "\n",
    "print(conv1.code)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def conv1(a: Tensor,\n",
      "    b: Tensor) -> Tensor:\n",
      "  na, = torch.size(a)\n",
      "  nb, = torch.size(b)\n",
      "  out = torch.empty([torch.add(torch.sub(na, nb), 1)])\n",
      "  for ia in range(torch.add(torch.sub(na, nb), 1)):\n",
      "    _0 = annotate(List[Tensor], [])\n",
      "    for ib in range(na):\n",
      "      _1 = torch.select(a, 0, torch.add(ia, ib))\n",
      "      _2 = torch.mul(_1, torch.select(b, 0, ib))\n",
      "      _3 = torch.append(_0, _2)\n",
      "    _4 = torch.sum(torch.tensor(_0))\n",
      "    _5 = torch.copy_(torch.select(out, 0, ia), _4)\n",
      "  return out\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def ratio_iou(x1, y1, w1, h1, x2, y2, w2, h2):\n",
    "    xi = torch.max(x1, x2)                                  # Intersection left\n",
    "    yi = torch.max(y1, y2)                                  # Intersection top\n",
    "    wi = torch.clamp(torch.min(x1+w1, x2+w2) - xi, min=0.)  # Intersection width\n",
    "    hi = torch.clamp(torch.min(y1+h1, y2+h2) - yi, min=0.)  # Intersection height\n",
    "    area_i = wi * hi                                        # Area Intersection\n",
    "    area_u = w1 * h1 + w2 * h2 - wi * hi                    # Area Union\n",
    "    return area_i / torch.clamp(area_u, min=1e-5)           # Intersection over Union\n",
    "\n",
    "import torch.jit\n",
    "\n",
    "with torch.jit.optimized_execution(True):\n",
    "  ratio_iou_scripted = torch.jit.script(ratio_iou)\n",
    "\n",
    "  print(ratio_iou_scripted.code)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def ratio_iou(x1: Tensor,\n",
      "    y1: Tensor,\n",
      "    w1: Tensor,\n",
      "    h1: Tensor,\n",
      "    x2: Tensor,\n",
      "    y2: Tensor,\n",
      "    w2: Tensor,\n",
      "    h2: Tensor) -> Tensor:\n",
      "  xi = torch.max(x1, x2)\n",
      "  yi = torch.max(y1, y2)\n",
      "  _0 = torch.min(torch.add(x1, w1), torch.add(x2, w2))\n",
      "  wi = torch.clamp(torch.sub(_0, xi), 0.)\n",
      "  _1 = torch.min(torch.add(y1, h1), torch.add(y2, h2))\n",
      "  hi = torch.clamp(torch.sub(_1, yi), 0.)\n",
      "  area_i = torch.mul(wi, hi)\n",
      "  _2 = torch.add(torch.mul(w1, h1), torch.mul(w2, h2))\n",
      "  area_u = torch.sub(_2, torch.mul(wi, hi))\n",
      "  _3 = torch.clamp(area_u, 1.0000000000000001e-05)\n",
      "  return torch.div(area_i, _3)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# we make a scripted function\n",
    "ratio_iou_scripted = torch.jit.script(ratio_iou)\n",
    "\n",
    "x1, y1, w1, h1, x2, y2, w2, h2 = torch.randn(8, 100, 1000, device='cuda', requires_grad=True).exp()\n",
    "\n",
    "ratio_iou_scripted(x1, y1, w1, h1, x2, y2, w2, h2)\n",
    "\n",
    "print(ratio_iou_scripted.graph_for(x1, y1, w1, h1, x2, y2, w2, h2))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "graph(%x1.1 : Tensor,\n",
      "      %y1.1 : Tensor,\n",
      "      %w1.1 : Tensor,\n",
      "      %h1.1 : Tensor,\n",
      "      %x2.1 : Tensor,\n",
      "      %y2.1 : Tensor,\n",
      "      %w2.1 : Tensor,\n",
      "      %h2.1 : Tensor):\n",
      "  %8 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %9 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %10 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %11 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %12 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %13 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %14 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %15 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), %16 : bool = prim::TypeCheck[types=[Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0), Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0)]](%w2.1, %h2.1, %w1.1, %h1.1, %y2.1, %y1.1, %x2.1, %x1.1)\n",
      "  %17 : Tensor = prim::If(%16)\n",
      "    block0():\n",
      "      %18 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = prim::TensorExprGroup_0(%8, %9, %10, %11, %12, %13, %14, %15)\n",
      "      -> (%18)\n",
      "    block1():\n",
      "      %19 : Function = prim::Constant[name=\"fallback_function\", fallback=1]()\n",
      "      %20 : (Tensor) = prim::CallFunction(%19, %w2.1, %h2.1, %w1.1, %h1.1, %y2.1, %y1.1, %x2.1, %x1.1)\n",
      "      %21 : Tensor = prim::TupleUnpack(%20)\n",
      "      -> (%21)\n",
      "  return (%17)\n",
      "with prim::TensorExprGroup_0 = graph(%w2.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %h2.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %w1.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %h1.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %y2.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %y1.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %x2.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0),\n",
      "      %x1.1 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0)):\n",
      "  %8 : float = prim::Constant[value=1.0000000000000001e-05]()\n",
      "  %9 : NoneType = prim::Constant()\n",
      "  %10 : float = prim::Constant[value=0.]()\n",
      "  %11 : int = prim::Constant[value=1]()\n",
      "  %xi.2 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::max(%x1.1, %x2.1) # /tmp/ipykernel_37729/409060614.py:2:9\n",
      "  %yi.2 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::max(%y1.1, %y2.1) # /tmp/ipykernel_37729/409060614.py:3:9\n",
      "  %14 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::add(%x1.1, %w1.1, %11) # /tmp/ipykernel_37729/409060614.py:4:31\n",
      "  %15 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::add(%x2.1, %w2.1, %11) # /tmp/ipykernel_37729/409060614.py:4:38\n",
      "  %16 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::min(%14, %15) # /tmp/ipykernel_37729/409060614.py:4:21\n",
      "  %17 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::sub(%16, %xi.2, %11) # /tmp/ipykernel_37729/409060614.py:4:21\n",
      "  %wi.2 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::clamp(%17, %10, %9) # /tmp/ipykernel_37729/409060614.py:4:9\n",
      "  %19 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::add(%y1.1, %h1.1, %11) # /tmp/ipykernel_37729/409060614.py:5:31\n",
      "  %20 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::add(%y2.1, %h2.1, %11) # /tmp/ipykernel_37729/409060614.py:5:38\n",
      "  %21 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::min(%19, %20) # /tmp/ipykernel_37729/409060614.py:5:21\n",
      "  %22 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::sub(%21, %yi.2, %11) # /tmp/ipykernel_37729/409060614.py:5:21\n",
      "  %hi.2 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::clamp(%22, %10, %9) # /tmp/ipykernel_37729/409060614.py:5:9\n",
      "  %area_i.2 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::mul(%wi.2, %hi.2) # /tmp/ipykernel_37729/409060614.py:6:13\n",
      "  %25 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::mul(%w1.1, %h1.1) # /tmp/ipykernel_37729/409060614.py:7:13\n",
      "  %26 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::mul(%w2.1, %h2.1) # /tmp/ipykernel_37729/409060614.py:7:23\n",
      "  %27 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::add(%25, %26, %11) # /tmp/ipykernel_37729/409060614.py:7:13\n",
      "  %area_u.2 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::sub(%27, %area_i.2, %11) # /tmp/ipykernel_37729/409060614.py:7:13\n",
      "  %29 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::clamp(%area_u.2, %8, %9) # /tmp/ipykernel_37729/409060614.py:8:20\n",
      "  %30 : Float(100, 1000, strides=[1000, 1], requires_grad=0, device=cuda:0) = aten::div(%area_i.2, %29) # /tmp/ipykernel_37729/409060614.py:8:11\n",
      "  return (%30)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('knossos': conda)"
  },
  "interpreter": {
   "hash": "f824ef975b63b5bc7533c466a92ceff3da98064c70ac37413c2f4ee9f9f9fed2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}