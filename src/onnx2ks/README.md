## ONNX2KS: Convert onnx files to Knossos IR

There are two main components:

  - onnx-build-prelude: Converts schemas in onnx.defs.get_all_schemas to ks, emitting `etc/onnx-prelude*.ks`
  - onnx2ks: Read a .onnx file, generate a .ks which expresses the same computation (see mnist example below)

It has *not* yet been executed/roundtripped.  Next steps are to 
  - transform back to ONNX
  - lower to MLIR/C++ and measure performance.  

Clarifies several concepts in ONNX, some of which don't (shouldn't?) exist in KS, e.g. 

### Attributes and inputs

KS has only inputs, constant parameters can be optimized by OTP.   In some cases, attributes dispatch to different implementations, e.g. one might imagine translating 
```
MatMul[transposeA=1,transposeB=0](A,B)
```
to `(MatMul A B 1 0)`, but then exposing the switch using an inlineable `def` in the prelude, as follows.  Then the inliner can inline the `def` to expose rewrite opportunities, and eliminate dead code, while the core functions remain clean.
```
(edef MatMul (Tensor Float) ((Tensor Float) (Tensor Float))
(def MatMul (Tensor Float) ((A : Tensor Float) (B : Tensor Float) (transposeA : Integer) (transposeB : Integer)
    (if transposeA  
    (if transposeB
        (MatMul (Transpose A) (Transpose B))
        (MatMul (Transpose A) B))
    (if transposeB
        (MatMul A (Transpose B))
        (MatMul A B))))
```
Similarly, if the attributes dispatch to differently optimized core functions, as is wise for MatMul, that can be exposed by rewrites
```
(rule (MatMul (Transpose A) (Transpose B)) (Transpose (MatMul B A)))
(rule (MatMul A (Transpose B)) (MatMulAtB A B))
```

### Type constraints

ONNX has some slightly tricky rules to declare the same op over multiple types.
Knossos has ad-hoc overloading, so we just emit the same name with each acceptable type combo.
This leads to 25 decls for SequenceInsert, but it's seriously not a biggie in the scheme 
of things.  Think of it as C++ templates.

###  Optional inputs

Emits one type signature for each callable version of the function

###  Optional outputs

Emits versions of the function of the form "take1$foo" to auto-discard the outputs.

## Usage: onnnx2ks

onnx2ks.py: Read ONNX file and emit .ks, e.g. the below from mnist-7.

```clojure
;; AUTOGENERATED FROM test/onnx2ks/mnist-7.onnx
(def CNTKGraph
     (Tensor 2 Float)
     ((Input3 : (Tensor 4 Float))
      (Parameter5 : (Tensor 4 Float))
      (Parameter6 : (Tensor 3 Float))
      (Parameter87 : (Tensor 4 Float))
      (Parameter88 : (Tensor 3 Float))
      (Pooling160_Output_0_reshape0_shape : (Tensor 1 Integer))
      (Parameter193 : (Tensor 4 Float))
      (Parameter193_reshape1_shape : (Tensor 1 Integer))
      (Parameter194 : (Tensor 2 Float)))
  (let ($beg_of_internal_inits #|Begin of internal initializers|#  99999)
  (let ($end_of_inits #|End of initializers|#  99999)
  (let (Parameter193_reshape1 (Reshape Parameter193 Parameter193_reshape1_shape))
  (let (Convolution28_Output_0 (Conv Input3 Parameter5 "SAME_UPPER" (Vec_init 1 1) 1 (Vec_init 5 5) (Vec_init -1 -1) (Vec_init 1 1)))
  (let (Plus30_Output_0 (Add Convolution28_Output_0 Parameter6))
  (let (ReLU32_Output_0 (Relu Plus30_Output_0))
  (let (Pooling66_Output_0 (take1$MaxPool ReLU32_Output_0 "NOTSET" 0 (Vec_init 1 1) (Vec_init 2 2) (Vec_init 0 0 0 0) 0 (Vec_init 2 2)))
  (let (Convolution110_Output_0 (Conv Pooling66_Output_0 Parameter87 "SAME_UPPER" (Vec_init 1 1) 1 (Vec_init 5 5) (Vec_init -1 -1) (Vec_init 1 1)))
  (let (Plus112_Output_0 (Add Convolution110_Output_0 Parameter88))
  (let (ReLU114_Output_0 (Relu Plus112_Output_0))
  (let (Pooling160_Output_0 (take1$MaxPool ReLU114_Output_0 "NOTSET" 0 (Vec_init 1 1) (Vec_init 3 3) (Vec_init 0 0 0 0) 0 (Vec_init 3 3)))
  (let (Pooling160_Output_0_reshape0 (Reshape Pooling160_Output_0 Pooling160_Output_0_reshape0_shape))
  (let (Times212_Output_0 (MatMul Pooling160_Output_0_reshape0 Parameter193_reshape1))
  (let (Plus214_Output_0 (Add Times212_Output_0 Parameter194))
  Plus214_Output_0)))))))))))))))

(def main (Tensor 2 Float) ((Input3 : (Tensor 4 Float)))
  (let (Parameter5 (load-from-onnx-float32 8 1 5 5 "Parameter5"))
  (let (Parameter6 (load-from-onnx-float32 8 1 1 "Parameter6"))
  (let (Parameter87 (load-from-onnx-float32 16 8 5 5 "Parameter87"))
  (let (Parameter88 (load-from-onnx-float32 16 1 1 "Parameter88"))
  (let (Pooling160_Output_0_reshape0_shape (Vec_init 1 256))
  (let (Parameter193 (load-from-onnx-float32 16 4 4 10 "Parameter193"))
  (let (Parameter193_reshape1_shape (Vec_init 256 10))
  (let (Parameter194 (load-from-onnx-float32 1 10 "Parameter194"))
  (CNTKGraph Input3 Parameter5 Parameter6 Parameter87 Parameter88 Pooling160_Output_0_reshape0_shape Parameter193 Parameter193_reshape1_shape Parameter194))))))))))
```

## Building

Install onnxruntime
```sh
$ cd ../onnxruntime
$ ./build.sh --enable_training --gen_doc  --config=RelWithDebInfo --build_wheel
$ pip install --upgrade ./build/Linux/RelWithDebInfo/dist/onnxruntime-1.5.2-cp38-cp38-linux_x86_64.whl
```

Ensure you're using the compatible ONNX
```sh
$ cd ../onnxruntime/cmake/external/onnx
$ python setup.py install
```

Build the prelude `etc/onnx-prelude-autogen.ks`
```sh
$ cd ../knossos-ksc
$ python src/onnx2ks/onnx-build-prelude.py
Test test_all_combinations_type_constraints
src/onnx2ks/onnx-build-prelude.py:305: UserWarning: Optional attribute without default value ignore_index
  warnings.warn(f"Optional attribute without default value {a.name}")
...
Processing schemas: MemcpyFromHost[x5] com.microsoft.FastGeluGrad com.microsoft.SliceGrad[x5] com.microsoft.Recv com.microsoft.All com.microsoft.IsFinite com.microsoft.Group[x5] com.microsoft.BiasFastGeluGrad_dX com.microsoft.BatchNormalizationGrad ...
Wrote schemas to etc/onnx-prelude-autogen.ks
```

And then translate a file.
```sh
$ python src/onnx2ks/onnx2ks.py test/onnx2ks/mnist-7.onnx obj/
onnx2ks: Reading from test/onnx2ks/mnist-7.onnx
onnx2ks: Making output dir obj/test/onnx2ks
onnx2ks: Writing graph to obj/test/onnx2ks/mnist-7.onnx.txt
** Attribute dilations of op MaxPool has no default value -- special casing
** Attribute pads of op Conv has no default value -- special casing
** Attribute dilations of op MaxPool has no default value -- special casing
** Attribute pads of op Conv has no default value -- special casing
onnx2ks: Writing to obj/test/onnx2ks/mnist-7.untyped.ks
onnx2ks: Writing to obj/test/onnx2ks/mnist-7.ks
```
